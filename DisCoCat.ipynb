{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import discopy\n",
    "from discopy.grammar import pregroup\n",
    "\n",
    "# Assuming your file is named 'sentences.txt' and each line is a sentence\n",
    "with open('russian_latin.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "# Define your vocabulary (replace with your actual vocabulary)\n",
    "vocabulary = {\n",
    "    'марш': pregroup.noun,\n",
    "    'иди': pregroup.verb,\n",
    "    # ... add all your words\n",
    "}\n",
    "\n",
    "# Define your grammar (replace with your actual grammar rules)\n",
    "grammar = pregroup.grammar\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip()  # Remove leading/trailing whitespace\n",
    "    words = sentence.split()  # Split the sentence into words\n",
    "\n",
    "    # Convert words to DiscoPy terms\n",
    "    terms = [vocabulary.get(word, None) for word in words]\n",
    "\n",
    "    # Remove unknown words (or handle them appropriately)\n",
    "    terms = [term for term in terms if term is not None]\n",
    "\n",
    "    # If the sentence is empty after removing unknown words, skip it\n",
    "    if not terms:\n",
    "        continue\n",
    "\n",
    "    # Create a DiscoPy diagram for the sentence\n",
    "    diagram = grammar.diagram(terms)\n",
    "\n",
    "    # Convert the diagram to a quantum circuit (if possible)\n",
    "    try:\n",
    "        circuit = diagram.to_quantum()\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(f\"Circuit: {circuit}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting sentence '{sentence}' to circuit: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (842801469.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python.exe -m pip install --upgrade pip\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English and Russian spaCy models\n",
    "try:\n",
    "    nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading English spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "try:\n",
    "    nlp_ru = spacy.load(\"ru_core_news_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading Russian spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"ru_core_news_sm\"])\n",
    "    nlp_ru = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "\n",
    "def tag_sentence(sentence, language):\n",
    "    if language == \"en\":\n",
    "        doc = nlp_en(sentence)\n",
    "    elif language == \"ru\":\n",
    "        doc = nlp_ru(sentence)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported language\")\n",
    "\n",
    "    tagged_words = [(token.text, token.pos_) for token in doc]\n",
    "    return tagged_words\n",
    "\n",
    "def process_file(filepath, language):  # Added language parameter\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file: # Added encoding for potential UTF-8 characters\n",
    "            for line in file:\n",
    "                sentence = line.strip()  # Remove leading/trailing whitespace\n",
    "                if sentence:  # Skip empty lines\n",
    "                    tagged_sentence = tag_sentence(sentence, language)\n",
    "                    print(f\"Sentence: {sentence}\")\n",
    "                    print(f\"Tagged: {tagged_sentence}\")\n",
    "                    print(\"-\" * 20)  # Separator between sentences\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "    except Exception as e: # Catch other potential errors (e.g., UnicodeDecodeError)\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "english_file = \"english_sentences.txt\"\n",
    "russian_file = \"russian_sentences.txt\"\n",
    "\n",
    "process_file(english_file, \"en\")  # Process English sentences\n",
    "process_file(russian_file, \"ru\")  # Process Russian sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
